Training Model...
| Epoch:   1 | Batch:    200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0046 | Mean Training Loss: 11.0389 | Perplexity: 62251.6523 |
| Epoch:   1 | Batch:    400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 11.0378 | Perplexity: 62180.1523 |
| Epoch:   1 | Batch:    600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 11.0315 | Perplexity: 61791.6602 |
| Epoch:   1 | Batch:    800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 11.0268 | Perplexity: 61499.5312 |
| Epoch:   1 | Batch:   1000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 11.0282 | Perplexity: 61589.5703 |
| Epoch:   1 | Batch:   1200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 11.0274 | Perplexity: 61539.5469 |
| Epoch:   1 | Batch:   1400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 11.0247 | Perplexity: 61370.9883 |
| Epoch:   1 | Batch:   1600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 11.0251 | Perplexity: 61396.7422 |
| Epoch:   1 | Batch:   1800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 11.0234 | Perplexity: 61294.2500 |
| Epoch:   1 | Batch:   2000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 11.0207 | Perplexity: 61128.8672 |
| Epoch:   1 | Batch:   2200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 11.0198 | Perplexity: 61073.5664 |
| Epoch:   1 | Batch:   2400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 11.0040 | Perplexity: 60113.0703 |
| Epoch:   1 | Batch:   2600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0045 | Mean Training Loss: 11.0017 | Perplexity: 59973.1797 |
| Epoch:   1 | Batch:   2800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 10.9943 | Perplexity: 59536.3789 |
| Epoch:   1 | Batch:   3000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0043 | Mean Training Loss: 10.9866 | Perplexity: 59078.7539 |
| Epoch:   1 | Batch:   3200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0056 | Mean Training Loss: 10.9639 | Perplexity: 57753.8555 |
| Epoch:   1 | Batch:   3400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 10.9453 | Perplexity: 56685.3203 |
| Epoch:   1 | Batch:   3600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 10.9252 | Perplexity: 55556.6484 |
| Epoch:   1 | Batch:   3800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 10.9045 | Perplexity: 54418.1133 |
| Epoch:   1 | Batch:   4000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 10.8783 | Perplexity: 53015.9141 |
| Epoch:   1 | Batch:   4200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 10.8552 | Perplexity: 51802.5703 |
| Epoch:   1 | Batch:   4400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 10.8367 | Perplexity: 50851.9961 |
| Epoch:   1 | Batch:   4600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0036 | Mean Training Loss: 10.8330 | Perplexity: 50665.9648 |
| Epoch:   1 | Batch:   4800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0055 | Mean Training Loss: 10.8291 | Perplexity: 50470.6992 |
| Epoch:   1 | Batch:   5000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 10.8271 | Perplexity: 50369.0547 |
| Epoch:   1 | Batch:   5200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 10.8175 | Perplexity: 49887.2695 |
| Epoch:   1 | Batch:   5400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0039 | Mean Training Loss: 10.7961 | Perplexity: 48831.0000 |
| Epoch:   1 | Batch:   5600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 10.7896 | Perplexity: 48511.8398 |
| Epoch:   1 | Batch:   5800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 10.7179 | Perplexity: 45155.3906 |
| Epoch:   1 | Batch:   6000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 10.6387 | Perplexity: 41720.4297 |
| Epoch:   1 | Batch:   6200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 10.5848 | Perplexity: 39528.2227 |
| Epoch:   1 | Batch:   6400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0056 | Mean Training Loss: 10.5138 | Perplexity: 36818.7852 |
| Epoch:   1 | Batch:   6600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 10.5114 | Perplexity: 36731.0703 |
| Epoch:   1 | Batch:   6800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 10.5186 | Perplexity: 36996.7773 |
| Epoch:   1 | Batch:   7000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0052 | Mean Training Loss: 10.5205 | Perplexity: 37067.5547 |
| Epoch:   1 | Batch:   7200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 10.5287 | Perplexity: 37371.7852 |
| Epoch:   1 | Batch:   7400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 10.5378 | Perplexity: 37714.7148 |
| Epoch:   1 | Batch:   7600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 10.5467 | Perplexity: 38051.1328 |
| Epoch:   1 | Batch:   7800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0046 | Mean Training Loss: 10.5562 | Perplexity: 38413.0430 |
| Epoch:   1 | Batch:   8000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 10.5641 | Perplexity: 38720.8945 |
| Epoch:   1 | Batch:   8200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0060 | Mean Training Loss: 10.5705 | Perplexity: 38969.7266 |
| Epoch:   1 | Batch:   8400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 10.5769 | Perplexity: 39217.1328 |
| Epoch:   1 | Batch:   8600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 10.5829 | Perplexity: 39453.0156 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| End of Epoch:   1 | Time Taken: 48.2048 | Training Loss: 10.5853 | Training Perplexity: 39547.4922 | Validation Loss: 10.1460 | Validation Perplexity: 25488.6738 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| Epoch:   2 | Batch:    200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 10.3749 | Perplexity: 32045.9336 |
| Epoch:   2 | Batch:    400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0036 | Mean Training Loss: 10.4396 | Perplexity: 34186.4219 |
| Epoch:   2 | Batch:    600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 10.4163 | Perplexity: 33398.4414 |
| Epoch:   2 | Batch:    800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 10.4377 | Perplexity: 34121.0469 |
| Epoch:   2 | Batch:   1000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 10.5141 | Perplexity: 36830.8672 |
| Epoch:   2 | Batch:   1200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 10.5493 | Perplexity: 38150.8789 |
| Epoch:   2 | Batch:   1400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 10.5543 | Perplexity: 38340.7969 |
| Epoch:   2 | Batch:   1600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 10.5873 | Perplexity: 39628.6602 |
| Epoch:   2 | Batch:   1800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 10.6035 | Perplexity: 40273.6133 |
| Epoch:   2 | Batch:   2000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 10.5981 | Perplexity: 40056.8477 |
| Epoch:   2 | Batch:   2200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 10.6076 | Perplexity: 40439.6055 |
| Epoch:   2 | Batch:   2400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 10.5163 | Perplexity: 36911.0391 |
| Epoch:   2 | Batch:   2600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 10.5195 | Perplexity: 37030.9844 |
| Epoch:   2 | Batch:   2800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 10.4930 | Perplexity: 36063.2148 |
| Epoch:   2 | Batch:   3000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 10.4751 | Perplexity: 35423.3750 |
| Epoch:   2 | Batch:   3200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0046 | Mean Training Loss: 10.4084 | Perplexity: 33135.2461 |
| Epoch:   2 | Batch:   3400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 10.3675 | Perplexity: 31808.2266 |
| Epoch:   2 | Batch:   3600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 10.3375 | Perplexity: 30869.8672 |
| Epoch:   2 | Batch:   3800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0044 | Mean Training Loss: 10.3113 | Perplexity: 30071.6016 |
| Epoch:   2 | Batch:   4000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0046 | Mean Training Loss: 10.2831 | Perplexity: 29235.4238 |
| Epoch:   2 | Batch:   4200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 10.2617 | Perplexity: 28615.5723 |
| Epoch:   2 | Batch:   4400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 10.2494 | Perplexity: 28266.2266 |
| Epoch:   2 | Batch:   4600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 10.2567 | Perplexity: 28473.7988 |
| Epoch:   2 | Batch:   4800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 10.2643 | Perplexity: 28690.9648 |
| Epoch:   2 | Batch:   5000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 10.2732 | Perplexity: 28945.4844 |
| Epoch:   2 | Batch:   5200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 10.2723 | Perplexity: 28921.6719 |
| Epoch:   2 | Batch:   5400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 10.2585 | Perplexity: 28523.9180 |
| Epoch:   2 | Batch:   5600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 10.2617 | Perplexity: 28614.6172 |
| Epoch:   2 | Batch:   5800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 10.1926 | Perplexity: 26705.7090 |
| Epoch:   2 | Batch:   6000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 10.1165 | Perplexity: 24748.9668 |
| Epoch:   2 | Batch:   6200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 10.0688 | Perplexity: 23594.2441 |
| Epoch:   2 | Batch:   6400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 10.0019 | Perplexity: 22068.8555 |
| Epoch:   2 | Batch:   6600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 10.0096 | Perplexity: 22237.9551 |
| Epoch:   2 | Batch:   6800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 10.0263 | Perplexity: 22614.0391 |
| Epoch:   2 | Batch:   7000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 10.0365 | Perplexity: 22845.9805 |
| Epoch:   2 | Batch:   7200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 10.0526 | Perplexity: 23217.1309 |
| Epoch:   2 | Batch:   7400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 10.0697 | Perplexity: 23617.2949 |
| Epoch:   2 | Batch:   7600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 10.0859 | Perplexity: 24002.3945 |
| Epoch:   2 | Batch:   7800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0060 | Mean Training Loss: 10.1024 | Perplexity: 24400.7305 |
| Epoch:   2 | Batch:   8000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 10.1169 | Perplexity: 24757.5117 |
| Epoch:   2 | Batch:   8200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 10.1284 | Perplexity: 25044.2344 |
| Epoch:   2 | Batch:   8400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 10.1391 | Perplexity: 25314.4473 |
| Epoch:   2 | Batch:   8600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 10.1501 | Perplexity: 25593.3867 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| End of Epoch:   2 | Time Taken: 48.7979 | Training Loss: 10.1552 | Training Perplexity: 25724.4004 | Validation Loss: 9.8936 | Validation Perplexity: 19803.6855 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| Epoch:   3 | Batch:    200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 10.1107 | Perplexity: 24604.6816 |
| Epoch:   3 | Batch:    400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 10.1924 | Perplexity: 26699.3164 |
| Epoch:   3 | Batch:    600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 10.1527 | Perplexity: 25661.5254 |
| Epoch:   3 | Batch:    800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 10.1814 | Perplexity: 26408.3262 |
| Epoch:   3 | Batch:   1000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 10.2691 | Perplexity: 28828.2363 |
| Epoch:   3 | Batch:   1200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0046 | Mean Training Loss: 10.3144 | Perplexity: 30163.0801 |
| Epoch:   3 | Batch:   1400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 10.3134 | Perplexity: 30134.7871 |
| Epoch:   3 | Batch:   1600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 10.3494 | Perplexity: 31237.1484 |
| Epoch:   3 | Batch:   1800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 10.3689 | Perplexity: 31852.2734 |
| Epoch:   3 | Batch:   2000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 10.3593 | Perplexity: 31548.6562 |
| Epoch:   3 | Batch:   2200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 10.3683 | Perplexity: 31835.0234 |
| Epoch:   3 | Batch:   2400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0069 | Mean Training Loss: 10.2556 | Perplexity: 28441.0684 |
| Epoch:   3 | Batch:   2600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 10.2568 | Perplexity: 28475.8086 |
| Epoch:   3 | Batch:   2800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 10.2273 | Perplexity: 27648.3828 |
| Epoch:   3 | Batch:   3000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 10.2119 | Perplexity: 27225.4219 |
| Epoch:   3 | Batch:   3200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 10.1424 | Perplexity: 25396.6875 |
| Epoch:   3 | Batch:   3400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 10.0985 | Perplexity: 24305.8105 |
| Epoch:   3 | Batch:   3600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 10.0684 | Perplexity: 23585.7402 |
| Epoch:   3 | Batch:   3800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 10.0413 | Perplexity: 22956.0332 |
| Epoch:   3 | Batch:   4000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0058 | Mean Training Loss: 10.0118 | Perplexity: 22287.3809 |
| Epoch:   3 | Batch:   4200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.9867 | Perplexity: 21736.4688 |
| Epoch:   3 | Batch:   4400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.9723 | Perplexity: 21424.5527 |
| Epoch:   3 | Batch:   4600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.9778 | Perplexity: 21542.7715 |
| Epoch:   3 | Batch:   4800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.9850 | Perplexity: 21699.3555 |
| Epoch:   3 | Batch:   5000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0052 | Mean Training Loss: 9.9929 | Perplexity: 21869.8574 |
| Epoch:   3 | Batch:   5200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.9910 | Perplexity: 21829.3496 |
| Epoch:   3 | Batch:   5400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.9763 | Perplexity: 21510.5820 |
| Epoch:   3 | Batch:   5600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.9804 | Perplexity: 21598.0664 |
| Epoch:   3 | Batch:   5800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.9112 | Perplexity: 20155.2031 |
| Epoch:   3 | Batch:   6000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.8350 | Perplexity: 18675.5332 |
| Epoch:   3 | Batch:   6200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.7878 | Perplexity: 17815.4062 |
| Epoch:   3 | Batch:   6400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.7215 | Perplexity: 16671.9863 |
| Epoch:   3 | Batch:   6600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.7324 | Perplexity: 16854.2305 |
| Epoch:   3 | Batch:   6800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.7514 | Perplexity: 17178.5234 |
| Epoch:   3 | Batch:   7000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.7632 | Perplexity: 17382.5273 |
| Epoch:   3 | Batch:   7200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.7809 | Perplexity: 17691.8770 |
| Epoch:   3 | Batch:   7400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.7994 | Perplexity: 18022.5898 |
| Epoch:   3 | Batch:   7600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.8172 | Perplexity: 18345.9902 |
| Epoch:   3 | Batch:   7800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.8350 | Perplexity: 18676.5645 |
| Epoch:   3 | Batch:   8000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.8514 | Perplexity: 18984.8691 |
| Epoch:   3 | Batch:   8200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.8631 | Perplexity: 19209.1855 |
| Epoch:   3 | Batch:   8400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.8740 | Perplexity: 19419.4434 |
| Epoch:   3 | Batch:   8600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.8856 | Perplexity: 19645.5820 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| End of Epoch:   3 | Time Taken: 49.0674 | Training Loss: 9.8907 | Training Perplexity: 19745.0938 | Validation Loss: 9.5990 | Validation Perplexity: 14749.3477 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| Epoch:   4 | Batch:    200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.8344 | Perplexity: 18665.7402 |
| Epoch:   4 | Batch:    400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.9392 | Perplexity: 20727.4805 |
| Epoch:   4 | Batch:    600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.8891 | Perplexity: 19713.7090 |
| Epoch:   4 | Batch:    800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.9282 | Perplexity: 20500.0508 |
| Epoch:   4 | Batch:   1000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 10.0267 | Perplexity: 22621.7812 |
| Epoch:   4 | Batch:   1200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 10.0814 | Perplexity: 23894.5254 |
| Epoch:   4 | Batch:   1400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 10.0797 | Perplexity: 23853.7949 |
| Epoch:   4 | Batch:   1600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 10.1186 | Perplexity: 24799.0527 |
| Epoch:   4 | Batch:   1800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0052 | Mean Training Loss: 10.1436 | Perplexity: 25428.1680 |
| Epoch:   4 | Batch:   2000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 10.1325 | Perplexity: 25147.4121 |
| Epoch:   4 | Batch:   2200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 10.1420 | Perplexity: 25388.2852 |
| Epoch:   4 | Batch:   2400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 10.0195 | Perplexity: 22459.9766 |
| Epoch:   4 | Batch:   2600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 10.0208 | Perplexity: 22489.6621 |
| Epoch:   4 | Batch:   2800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.9893 | Perplexity: 21791.9102 |
| Epoch:   4 | Batch:   3000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.9769 | Perplexity: 21524.1641 |
| Epoch:   4 | Batch:   3200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.9069 | Perplexity: 20067.7051 |
| Epoch:   4 | Batch:   3400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.8615 | Perplexity: 19178.3438 |
| Epoch:   4 | Batch:   3600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.8326 | Perplexity: 18631.3965 |
| Epoch:   4 | Batch:   3800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.8055 | Perplexity: 18133.8613 |
| Epoch:   4 | Batch:   4000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.7756 | Perplexity: 17598.2148 |
| Epoch:   4 | Batch:   4200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.7483 | Perplexity: 17125.4609 |
| Epoch:   4 | Batch:   4400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.7328 | Perplexity: 16862.3652 |
| Epoch:   4 | Batch:   4600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.7382 | Perplexity: 16952.5156 |
| Epoch:   4 | Batch:   4800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0052 | Mean Training Loss: 9.7463 | Perplexity: 17091.2129 |
| Epoch:   4 | Batch:   5000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0052 | Mean Training Loss: 9.7545 | Perplexity: 17232.2441 |
| Epoch:   4 | Batch:   5200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.7531 | Perplexity: 17207.6777 |
| Epoch:   4 | Batch:   5400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.7388 | Perplexity: 16963.1738 |
| Epoch:   4 | Batch:   5600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.7440 | Perplexity: 17050.8047 |
| Epoch:   4 | Batch:   5800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.6753 | Perplexity: 15919.0830 |
| Epoch:   4 | Batch:   6000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.6000 | Perplexity: 14764.2373 |
| Epoch:   4 | Batch:   6200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0040 | Mean Training Loss: 9.5545 | Perplexity: 14108.1270 |
| Epoch:   4 | Batch:   6400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.4892 | Perplexity: 13215.6963 |
| Epoch:   4 | Batch:   6600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.5031 | Perplexity: 13401.6465 |
| Epoch:   4 | Batch:   6800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.5243 | Perplexity: 13687.7520 |
| Epoch:   4 | Batch:   7000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.5376 | Perplexity: 13871.9131 |
| Epoch:   4 | Batch:   7200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.5570 | Perplexity: 14142.6660 |
| Epoch:   4 | Batch:   7400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.5774 | Perplexity: 14434.3193 |
| Epoch:   4 | Batch:   7600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 9.5970 | Perplexity: 14719.8242 |
| Epoch:   4 | Batch:   7800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.6162 | Perplexity: 15006.4111 |
| Epoch:   4 | Batch:   8000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0054 | Mean Training Loss: 9.6341 | Perplexity: 15276.8252 |
| Epoch:   4 | Batch:   8200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.6467 | Perplexity: 15470.6348 |
| Epoch:   4 | Batch:   8400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.6582 | Perplexity: 15648.9365 |
| Epoch:   4 | Batch:   8600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.6709 | Perplexity: 15850.2314 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| End of Epoch:   4 | Time Taken: 49.1155 | Training Loss: 9.6764 | Training Perplexity: 15936.6572 | Validation Loss: 9.4014 | Validation Perplexity: 12105.3701 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| Epoch:   5 | Batch:    200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0059 | Mean Training Loss: 9.6428 | Perplexity: 15411.1719 |
| Epoch:   5 | Batch:    400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.7566 | Perplexity: 17267.1523 |
| Epoch:   5 | Batch:    600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.6982 | Perplexity: 16287.6592 |
| Epoch:   5 | Batch:    800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.7433 | Perplexity: 17040.4355 |
| Epoch:   5 | Batch:   1000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.8511 | Perplexity: 18979.2734 |
| Epoch:   5 | Batch:   1200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.9117 | Perplexity: 20163.9883 |
| Epoch:   5 | Batch:   1400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.9106 | Perplexity: 20143.6348 |
| Epoch:   5 | Batch:   1600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.9505 | Perplexity: 20962.7520 |
| Epoch:   5 | Batch:   1800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.9794 | Perplexity: 21576.8828 |
| Epoch:   5 | Batch:   2000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0044 | Mean Training Loss: 9.9666 | Perplexity: 21302.2891 |
| Epoch:   5 | Batch:   2200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 9.9770 | Perplexity: 21526.0332 |
| Epoch:   5 | Batch:   2400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.8469 | Perplexity: 18900.2148 |
| Epoch:   5 | Batch:   2600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.8485 | Perplexity: 18930.5938 |
| Epoch:   5 | Batch:   2800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.8161 | Perplexity: 18325.7227 |
| Epoch:   5 | Batch:   3000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.8052 | Perplexity: 18127.5156 |
| Epoch:   5 | Batch:   3200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.7339 | Perplexity: 16880.8691 |
| Epoch:   5 | Batch:   3400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.6871 | Perplexity: 16108.4990 |
| Epoch:   5 | Batch:   3600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.6578 | Perplexity: 15644.0273 |
| Epoch:   5 | Batch:   3800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.6297 | Perplexity: 15209.8389 |
| Epoch:   5 | Batch:   4000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.5987 | Perplexity: 14744.8906 |
| Epoch:   5 | Batch:   4200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 9.5705 | Perplexity: 14334.8906 |
| Epoch:   5 | Batch:   4400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.5546 | Perplexity: 14109.2979 |
| Epoch:   5 | Batch:   4600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.5599 | Perplexity: 14183.7959 |
| Epoch:   5 | Batch:   4800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.5686 | Perplexity: 14309.0342 |
| Epoch:   5 | Batch:   5000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.5773 | Perplexity: 14433.6035 |
| Epoch:   5 | Batch:   5200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.5763 | Perplexity: 14419.4053 |
| Epoch:   5 | Batch:   5400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.5625 | Perplexity: 14221.5449 |
| Epoch:   5 | Batch:   5600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.5688 | Perplexity: 14310.5215 |
| Epoch:   5 | Batch:   5800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.5001 | Perplexity: 13360.4912 |
| Epoch:   5 | Batch:   6000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.4253 | Perplexity: 12398.0195 |
| Epoch:   5 | Batch:   6200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 9.3808 | Perplexity: 11858.8398 |
| Epoch:   5 | Batch:   6400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.3158 | Perplexity: 11112.0498 |
| Epoch:   5 | Batch:   6600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.3321 | Perplexity: 11294.7070 |
| Epoch:   5 | Batch:   6800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.3548 | Perplexity: 11553.9434 |
| Epoch:   5 | Batch:   7000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.3692 | Perplexity: 11721.2285 |
| Epoch:   5 | Batch:   7200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.3898 | Perplexity: 11966.0039 |
| Epoch:   5 | Batch:   7400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.4117 | Perplexity: 12230.5430 |
| Epoch:   5 | Batch:   7600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.4324 | Perplexity: 12486.0625 |
| Epoch:   5 | Batch:   7800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.4525 | Perplexity: 12739.7256 |
| Epoch:   5 | Batch:   8000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.4715 | Perplexity: 12984.0820 |
| Epoch:   5 | Batch:   8200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.4848 | Perplexity: 13158.1865 |
| Epoch:   5 | Batch:   8400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.4965 | Perplexity: 13313.3037 |
| Epoch:   5 | Batch:   8600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0076 | Mean Training Loss: 9.5104 | Perplexity: 13499.3008 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| End of Epoch:   5 | Time Taken: 49.1277 | Training Loss: 9.5161 | Training Perplexity: 13576.8037 | Validation Loss: 9.2586 | Validation Perplexity: 10494.2432 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| Epoch:   6 | Batch:    200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.4967 | Perplexity: 13316.0596 |
| Epoch:   6 | Batch:    400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.6218 | Perplexity: 15090.2793 |
| Epoch:   6 | Batch:    600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.5564 | Perplexity: 14134.6436 |
| Epoch:   6 | Batch:    800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.6055 | Perplexity: 14846.4404 |
| Epoch:   6 | Batch:   1000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.7192 | Perplexity: 16633.4590 |
| Epoch:   6 | Batch:   1200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.7829 | Perplexity: 17728.3086 |
| Epoch:   6 | Batch:   1400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.7825 | Perplexity: 17720.7520 |
| Epoch:   6 | Batch:   1600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.8231 | Perplexity: 18454.6465 |
| Epoch:   6 | Batch:   1800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.8539 | Perplexity: 19031.8184 |
| Epoch:   6 | Batch:   2000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.8407 | Perplexity: 18782.5234 |
| Epoch:   6 | Batch:   2200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0045 | Mean Training Loss: 9.8526 | Perplexity: 19007.6953 |
| Epoch:   6 | Batch:   2400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.7190 | Perplexity: 16629.8730 |
| Epoch:   6 | Batch:   2600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.7204 | Perplexity: 16653.4746 |
| Epoch:   6 | Batch:   2800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.6872 | Perplexity: 16110.6338 |
| Epoch:   6 | Batch:   3000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0040 | Mean Training Loss: 9.6765 | Perplexity: 15939.1963 |
| Epoch:   6 | Batch:   3200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.6044 | Perplexity: 14829.7148 |
| Epoch:   6 | Batch:   3400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.5561 | Perplexity: 14130.5059 |
| Epoch:   6 | Batch:   3600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.5267 | Perplexity: 13720.6729 |
| Epoch:   6 | Batch:   3800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.4984 | Perplexity: 13337.9199 |
| Epoch:   6 | Batch:   4000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.4666 | Perplexity: 12921.3555 |
| Epoch:   6 | Batch:   4200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.4372 | Perplexity: 12545.9824 |
| Epoch:   6 | Batch:   4400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.4215 | Perplexity: 12350.8975 |
| Epoch:   6 | Batch:   4600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.4269 | Perplexity: 12418.5859 |
| Epoch:   6 | Batch:   4800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.4365 | Perplexity: 12538.3398 |
| Epoch:   6 | Batch:   5000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0070 | Mean Training Loss: 9.4456 | Perplexity: 12652.1973 |
| Epoch:   6 | Batch:   5200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 9.4451 | Perplexity: 12646.5879 |
| Epoch:   6 | Batch:   5400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.4315 | Perplexity: 12475.3857 |
| Epoch:   6 | Batch:   5600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.4386 | Perplexity: 12563.8711 |
| Epoch:   6 | Batch:   5800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.3701 | Perplexity: 11732.2998 |
| Epoch:   6 | Batch:   6000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.2961 | Perplexity: 10895.5439 |
| Epoch:   6 | Batch:   6200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.2531 | Perplexity: 10436.4658 |
| Epoch:   6 | Batch:   6400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.1888 | Perplexity: 9786.5713 |
| Epoch:   6 | Batch:   6600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 9.2069 | Perplexity: 9966.0420 |
| Epoch:   6 | Batch:   6800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.2312 | Perplexity: 10210.4092 |
| Epoch:   6 | Batch:   7000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.2465 | Perplexity: 10367.7295 |
| Epoch:   6 | Batch:   7200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 9.2681 | Perplexity: 10594.0859 |
| Epoch:   6 | Batch:   7400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0046 | Mean Training Loss: 9.2908 | Perplexity: 10838.3281 |
| Epoch:   6 | Batch:   7600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.3122 | Perplexity: 11072.2129 |
| Epoch:   6 | Batch:   7800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.3327 | Perplexity: 11301.7422 |
| Epoch:   6 | Batch:   8000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.3521 | Perplexity: 11523.5498 |
| Epoch:   6 | Batch:   8200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0054 | Mean Training Loss: 9.3661 | Perplexity: 11685.2891 |
| Epoch:   6 | Batch:   8400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.3780 | Perplexity: 11825.1182 |
| Epoch:   6 | Batch:   8600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0046 | Mean Training Loss: 9.3927 | Perplexity: 12000.1270 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| End of Epoch:   6 | Time Taken: 49.1334 | Training Loss: 9.3987 | Training Perplexity: 12072.4658 | Validation Loss: 9.1576 | Validation Perplexity: 9486.0586 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| Epoch:   7 | Batch:    200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.4042 | Perplexity: 12139.8555 |
| Epoch:   7 | Batch:    400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 9.5325 | Perplexity: 13801.0674 |
| Epoch:   7 | Batch:    600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.4606 | Perplexity: 12843.2803 |
| Epoch:   7 | Batch:    800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.5077 | Perplexity: 13463.5205 |
| Epoch:   7 | Batch:   1000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.6246 | Perplexity: 15132.6201 |
| Epoch:   7 | Batch:   1200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.6889 | Perplexity: 16137.5898 |
| Epoch:   7 | Batch:   1400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.6890 | Perplexity: 16138.7598 |
| Epoch:   7 | Batch:   1600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.7291 | Perplexity: 16799.1582 |
| Epoch:   7 | Batch:   1800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.7602 | Perplexity: 17330.5352 |
| Epoch:   7 | Batch:   2000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.7466 | Perplexity: 17096.3320 |
| Epoch:   7 | Batch:   2200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.7605 | Perplexity: 17334.8496 |
| Epoch:   7 | Batch:   2400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.6255 | Perplexity: 15146.4375 |
| Epoch:   7 | Batch:   2600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.6259 | Perplexity: 15151.7686 |
| Epoch:   7 | Batch:   2800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.5922 | Perplexity: 14650.4170 |
| Epoch:   7 | Batch:   3000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0052 | Mean Training Loss: 9.5814 | Perplexity: 14493.1221 |
| Epoch:   7 | Batch:   3200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.5087 | Perplexity: 13476.4678 |
| Epoch:   7 | Batch:   3400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.4600 | Perplexity: 12835.2480 |
| Epoch:   7 | Batch:   3600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.4309 | Perplexity: 12468.1416 |
| Epoch:   7 | Batch:   3800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.4031 | Perplexity: 12125.9941 |
| Epoch:   7 | Batch:   4000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.3703 | Perplexity: 11734.7393 |
| Epoch:   7 | Batch:   4200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.3394 | Perplexity: 11377.7451 |
| Epoch:   7 | Batch:   4400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.3240 | Perplexity: 11203.7012 |
| Epoch:   7 | Batch:   4600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.3297 | Perplexity: 11267.2617 |
| Epoch:   7 | Batch:   4800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.3396 | Perplexity: 11379.5469 |
| Epoch:   7 | Batch:   5000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0040 | Mean Training Loss: 9.3491 | Perplexity: 11488.6123 |
| Epoch:   7 | Batch:   5200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.3490 | Perplexity: 11486.7715 |
| Epoch:   7 | Batch:   5400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.3359 | Perplexity: 11338.1992 |
| Epoch:   7 | Batch:   5600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.3438 | Perplexity: 11427.5508 |
| Epoch:   7 | Batch:   5800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.2756 | Perplexity: 10674.2949 |
| Epoch:   7 | Batch:   6000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.2027 | Perplexity: 9923.7412 |
| Epoch:   7 | Batch:   6200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.1603 | Perplexity: 9512.1758 |
| Epoch:   7 | Batch:   6400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.0965 | Perplexity: 8924.4248 |
| Epoch:   7 | Batch:   6600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0054 | Mean Training Loss: 9.1158 | Perplexity: 9097.7275 |
| Epoch:   7 | Batch:   6800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.1412 | Perplexity: 9331.7705 |
| Epoch:   7 | Batch:   7000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.1569 | Perplexity: 9479.8281 |
| Epoch:   7 | Batch:   7200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.1788 | Perplexity: 9689.8848 |
| Epoch:   7 | Batch:   7400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.2019 | Perplexity: 9915.5215 |
| Epoch:   7 | Batch:   7600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.2234 | Perplexity: 10131.9375 |
| Epoch:   7 | Batch:   7800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 9.2438 | Perplexity: 10339.9326 |
| Epoch:   7 | Batch:   8000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.2634 | Perplexity: 10544.8457 |
| Epoch:   7 | Batch:   8200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 9.2776 | Perplexity: 10696.2646 |
| Epoch:   7 | Batch:   8400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.2892 | Perplexity: 10820.6973 |
| Epoch:   7 | Batch:   8600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.3044 | Perplexity: 10986.7285 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| End of Epoch:   7 | Time Taken: 49.1195 | Training Loss: 9.3107 | Training Perplexity: 11055.4258 | Validation Loss: 9.0808 | Validation Perplexity: 8784.5898 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| Epoch:   8 | Batch:    200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.3302 | Perplexity: 11273.3027 |
| Epoch:   8 | Batch:    400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.4642 | Perplexity: 12889.2695 |
| Epoch:   8 | Batch:    600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.3860 | Perplexity: 11919.8984 |
| Epoch:   8 | Batch:    800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0054 | Mean Training Loss: 9.4341 | Perplexity: 12507.1084 |
| Epoch:   8 | Batch:   1000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.5510 | Perplexity: 14059.0361 |
| Epoch:   8 | Batch:   1200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.6144 | Perplexity: 14979.6592 |
| Epoch:   8 | Batch:   1400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.6150 | Perplexity: 14988.1904 |
| Epoch:   8 | Batch:   1600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.6525 | Perplexity: 15560.5537 |
| Epoch:   8 | Batch:   1800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.6840 | Perplexity: 16058.2197 |
| Epoch:   8 | Batch:   2000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.6702 | Perplexity: 15838.2646 |
| Epoch:   8 | Batch:   2200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.6854 | Perplexity: 16080.8701 |
| Epoch:   8 | Batch:   2400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.5490 | Perplexity: 14031.0693 |
| Epoch:   8 | Batch:   2600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.5476 | Perplexity: 14010.8105 |
| Epoch:   8 | Batch:   2800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 9.5136 | Perplexity: 13542.9102 |
| Epoch:   8 | Batch:   3000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.5027 | Perplexity: 13395.2061 |
| Epoch:   8 | Batch:   3200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.4304 | Perplexity: 12461.9248 |
| Epoch:   8 | Batch:   3400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.3819 | Perplexity: 11870.9697 |
| Epoch:   8 | Batch:   3600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.3532 | Perplexity: 11536.2070 |
| Epoch:   8 | Batch:   3800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.3254 | Perplexity: 11219.7930 |
| Epoch:   8 | Batch:   4000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.2923 | Perplexity: 10853.7695 |
| Epoch:   8 | Batch:   4200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.2603 | Perplexity: 10512.6543 |
| Epoch:   8 | Batch:   4400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.2447 | Perplexity: 10349.4736 |
| Epoch:   8 | Batch:   4600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 9.2501 | Perplexity: 10405.3301 |
| Epoch:   8 | Batch:   4800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.2605 | Perplexity: 10514.1182 |
| Epoch:   8 | Batch:   5000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.2700 | Perplexity: 10615.1523 |
| Epoch:   8 | Batch:   5200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.2703 | Perplexity: 10617.9258 |
| Epoch:   8 | Batch:   5400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.2576 | Perplexity: 10483.6104 |
| Epoch:   8 | Batch:   5600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0029 | Mean Training Loss: 9.2661 | Perplexity: 10573.0518 |
| Epoch:   8 | Batch:   5800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.1990 | Perplexity: 9887.1650 |
| Epoch:   8 | Batch:   6000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.1272 | Perplexity: 9201.8613 |
| Epoch:   8 | Batch:   6200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.0860 | Perplexity: 8830.5186 |
| Epoch:   8 | Batch:   6400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.0231 | Perplexity: 8292.6406 |
| Epoch:   8 | Batch:   6600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.0430 | Perplexity: 8459.2559 |
| Epoch:   8 | Batch:   6800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0045 | Mean Training Loss: 9.0692 | Perplexity: 8683.8027 |
| Epoch:   8 | Batch:   7000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.0851 | Perplexity: 8823.2783 |
| Epoch:   8 | Batch:   7200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.1068 | Perplexity: 9016.8184 |
| Epoch:   8 | Batch:   7400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0052 | Mean Training Loss: 9.1298 | Perplexity: 9226.0879 |
| Epoch:   8 | Batch:   7600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.1512 | Perplexity: 9426.0078 |
| Epoch:   8 | Batch:   7800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.1712 | Perplexity: 9615.9814 |
| Epoch:   8 | Batch:   8000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.1907 | Perplexity: 9805.0967 |
| Epoch:   8 | Batch:   8200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.2050 | Perplexity: 9946.7002 |
| Epoch:   8 | Batch:   8400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.2158 | Perplexity: 10054.7588 |
| Epoch:   8 | Batch:   8600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.2311 | Perplexity: 10209.8447 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| End of Epoch:   8 | Time Taken: 49.1062 | Training Loss: 9.2374 | Training Perplexity: 10274.2812 | Validation Loss: 9.0151 | Validation Perplexity: 8226.4990 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| Epoch:   9 | Batch:    200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0036 | Mean Training Loss: 9.2699 | Perplexity: 10613.2783 |
| Epoch:   9 | Batch:    400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.4035 | Perplexity: 12130.7246 |
| Epoch:   9 | Batch:    600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.3206 | Perplexity: 11165.5039 |
| Epoch:   9 | Batch:    800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.3661 | Perplexity: 11684.9229 |
| Epoch:   9 | Batch:   1000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.4819 | Perplexity: 13120.0566 |
| Epoch:   9 | Batch:   1200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.5447 | Perplexity: 13969.9961 |
| Epoch:   9 | Batch:   1400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.5451 | Perplexity: 13975.6338 |
| Epoch:   9 | Batch:   1600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.5808 | Perplexity: 14484.6230 |
| Epoch:   9 | Batch:   1800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.6117 | Perplexity: 14938.2744 |
| Epoch:   9 | Batch:   2000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.5984 | Perplexity: 14740.5176 |
| Epoch:   9 | Batch:   2200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.6149 | Perplexity: 14986.2188 |
| Epoch:   9 | Batch:   2400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.4784 | Perplexity: 13073.7051 |
| Epoch:   9 | Batch:   2600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.4753 | Perplexity: 13033.3213 |
| Epoch:   9 | Batch:   2800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.4414 | Perplexity: 12599.8076 |
| Epoch:   9 | Batch:   3000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.4308 | Perplexity: 12466.3828 |
| Epoch:   9 | Batch:   3200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.3594 | Perplexity: 11607.1543 |
| Epoch:   9 | Batch:   3400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.3109 | Perplexity: 11057.5566 |
| Epoch:   9 | Batch:   3600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.2830 | Perplexity: 10754.0029 |
| Epoch:   9 | Batch:   3800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.2558 | Perplexity: 10465.4600 |
| Epoch:   9 | Batch:   4000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0038 | Mean Training Loss: 9.2222 | Perplexity: 10119.5566 |
| Epoch:   9 | Batch:   4200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.1899 | Perplexity: 9797.4414 |
| Epoch:   9 | Batch:   4400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.1745 | Perplexity: 9648.3623 |
| Epoch:   9 | Batch:   4600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.1800 | Perplexity: 9700.9805 |
| Epoch:   9 | Batch:   4800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 9.1903 | Perplexity: 9801.7588 |
| Epoch:   9 | Batch:   5000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0029 | Mean Training Loss: 9.2000 | Perplexity: 9897.3916 |
| Epoch:   9 | Batch:   5200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.2006 | Perplexity: 9903.4902 |
| Epoch:   9 | Batch:   5400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.1882 | Perplexity: 9781.1406 |
| Epoch:   9 | Batch:   5600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.1974 | Perplexity: 9870.9883 |
| Epoch:   9 | Batch:   5800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.1309 | Perplexity: 9236.2471 |
| Epoch:   9 | Batch:   6000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.0602 | Perplexity: 8605.5820 |
| Epoch:   9 | Batch:   6200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.0202 | Perplexity: 8268.7520 |
| Epoch:   9 | Batch:   6400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 8.9581 | Perplexity: 7770.9297 |
| Epoch:   9 | Batch:   6600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.9786 | Perplexity: 7931.5771 |
| Epoch:   9 | Batch:   6800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.0054 | Perplexity: 8147.2744 |
| Epoch:   9 | Batch:   7000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.0215 | Perplexity: 8278.8916 |
| Epoch:   9 | Batch:   7200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.0430 | Perplexity: 8459.4160 |
| Epoch:   9 | Batch:   7400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0033 | Mean Training Loss: 9.0657 | Perplexity: 8653.4463 |
| Epoch:   9 | Batch:   7600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.0869 | Perplexity: 8839.0615 |
| Epoch:   9 | Batch:   7800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.1063 | Perplexity: 9012.3223 |
| Epoch:   9 | Batch:   8000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.1256 | Perplexity: 9187.4102 |
| Epoch:   9 | Batch:   8200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.1399 | Perplexity: 9319.6572 |
| Epoch:   9 | Batch:   8400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.1500 | Perplexity: 9414.7598 |
| Epoch:   9 | Batch:   8600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0046 | Mean Training Loss: 9.1654 | Perplexity: 9560.9785 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| End of Epoch:   9 | Time Taken: 49.1084 | Training Loss: 9.1716 | Training Perplexity: 9620.2637 | Validation Loss: 8.9561 | Validation Perplexity: 7755.1973 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| Epoch:  10 | Batch:    200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 9.2129 | Perplexity: 10025.9082 |
| Epoch:  10 | Batch:    400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.3482 | Perplexity: 11477.7588 |
| Epoch:  10 | Batch:    600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.2623 | Perplexity: 10533.4482 |
| Epoch:  10 | Batch:    800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0063 | Mean Training Loss: 9.3075 | Perplexity: 11020.6143 |
| Epoch:  10 | Batch:   1000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.4205 | Perplexity: 12339.1484 |
| Epoch:  10 | Batch:   1200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.4814 | Perplexity: 13113.1514 |
| Epoch:  10 | Batch:   1400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.4820 | Perplexity: 13121.2578 |
| Epoch:  10 | Batch:   1600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.5158 | Perplexity: 13572.2480 |
| Epoch:  10 | Batch:   1800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 9.5464 | Perplexity: 13993.7178 |
| Epoch:  10 | Batch:   2000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.5338 | Perplexity: 13819.3086 |
| Epoch:  10 | Batch:   2200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.5511 | Perplexity: 14060.4971 |
| Epoch:  10 | Batch:   2400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.4139 | Perplexity: 12257.8916 |
| Epoch:  10 | Batch:   2600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.4087 | Perplexity: 12193.8223 |
| Epoch:  10 | Batch:   2800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.3752 | Perplexity: 11792.1230 |
| Epoch:  10 | Batch:   3000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.3645 | Perplexity: 11666.4150 |
| Epoch:  10 | Batch:   3200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0036 | Mean Training Loss: 9.2939 | Perplexity: 10871.1641 |
| Epoch:  10 | Batch:   3400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.2461 | Perplexity: 10364.1904 |
| Epoch:  10 | Batch:   3600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.2187 | Perplexity: 10084.2197 |
| Epoch:  10 | Batch:   3800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.1925 | Perplexity: 9822.9170 |
| Epoch:  10 | Batch:   4000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.1586 | Perplexity: 9495.8252 |
| Epoch:  10 | Batch:   4200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.1261 | Perplexity: 9191.8535 |
| Epoch:  10 | Batch:   4400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.1109 | Perplexity: 9053.5156 |
| Epoch:  10 | Batch:   4600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.1163 | Perplexity: 9102.2656 |
| Epoch:  10 | Batch:   4800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.1269 | Perplexity: 9199.1416 |
| Epoch:  10 | Batch:   5000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.1364 | Perplexity: 9287.4414 |
| Epoch:  10 | Batch:   5200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.1372 | Perplexity: 9295.1504 |
| Epoch:  10 | Batch:   5400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.1253 | Perplexity: 9184.9043 |
| Epoch:  10 | Batch:   5600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.1349 | Perplexity: 9273.7490 |
| Epoch:  10 | Batch:   5800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.0695 | Perplexity: 8686.4619 |
| Epoch:  10 | Batch:   6000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.0001 | Perplexity: 8104.2583 |
| Epoch:  10 | Batch:   6200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0030 | Mean Training Loss: 8.9610 | Perplexity: 7793.2690 |
| Epoch:  10 | Batch:   6400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.8994 | Perplexity: 7327.8320 |
| Epoch:  10 | Batch:   6600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.9203 | Perplexity: 7482.0874 |
| Epoch:  10 | Batch:   6800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0052 | Mean Training Loss: 8.9474 | Perplexity: 7688.0171 |
| Epoch:  10 | Batch:   7000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.9634 | Perplexity: 7811.9014 |
| Epoch:  10 | Batch:   7200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 8.9848 | Perplexity: 7980.6152 |
| Epoch:  10 | Batch:   7400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.0071 | Perplexity: 8160.4790 |
| Epoch:  10 | Batch:   7600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.0280 | Perplexity: 8333.3105 |
| Epoch:  10 | Batch:   7800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.0470 | Perplexity: 8492.9795 |
| Epoch:  10 | Batch:   8000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.0660 | Perplexity: 8655.5596 |
| Epoch:  10 | Batch:   8200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.0804 | Perplexity: 8781.4404 |
| Epoch:  10 | Batch:   8400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.0898 | Perplexity: 8864.0488 |
| Epoch:  10 | Batch:   8600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0046 | Mean Training Loss: 9.1054 | Perplexity: 9003.7744 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| End of Epoch:  10 | Time Taken: 49.0823 | Training Loss: 9.1117 | Training Perplexity: 9060.7715 | Validation Loss: 8.9014 | Validation Perplexity: 7342.5229 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| Epoch:  11 | Batch:    200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.1615 | Perplexity: 9523.1768 |
| Epoch:  11 | Batch:    400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 9.2984 | Perplexity: 10920.8438 |
| Epoch:  11 | Batch:    600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.2100 | Perplexity: 9996.2920 |
| Epoch:  11 | Batch:    800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.2524 | Perplexity: 10429.4219 |
| Epoch:  11 | Batch:   1000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.3633 | Perplexity: 11653.1836 |
| Epoch:  11 | Batch:   1200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.4220 | Perplexity: 12356.7412 |
| Epoch:  11 | Batch:   1400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.4235 | Perplexity: 12376.3301 |
| Epoch:  11 | Batch:   1600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.4558 | Perplexity: 12782.0752 |
| Epoch:  11 | Batch:   1800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.4862 | Perplexity: 13176.5713 |
| Epoch:  11 | Batch:   2000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.4741 | Perplexity: 13018.3779 |
| Epoch:  11 | Batch:   2200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.4919 | Perplexity: 13252.2842 |
| Epoch:  11 | Batch:   2400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.3542 | Perplexity: 11546.7402 |
| Epoch:  11 | Batch:   2600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0046 | Mean Training Loss: 9.3467 | Perplexity: 11460.9697 |
| Epoch:  11 | Batch:   2800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.3137 | Perplexity: 11089.3848 |
| Epoch:  11 | Batch:   3000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0045 | Mean Training Loss: 9.3022 | Perplexity: 10961.8516 |
| Epoch:  11 | Batch:   3200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.2325 | Perplexity: 10224.4307 |
| Epoch:  11 | Batch:   3400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.1850 | Perplexity: 9749.8584 |
| Epoch:  11 | Batch:   3600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.1584 | Perplexity: 9493.7334 |
| Epoch:  11 | Batch:   3800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.1331 | Perplexity: 9256.5898 |
| Epoch:  11 | Batch:   4000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.0997 | Perplexity: 8952.3164 |
| Epoch:  11 | Batch:   4200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.0670 | Perplexity: 8664.7764 |
| Epoch:  11 | Batch:   4400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.0522 | Perplexity: 8537.6523 |
| Epoch:  11 | Batch:   4600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.0576 | Perplexity: 8583.5830 |
| Epoch:  11 | Batch:   4800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.0683 | Perplexity: 8676.2207 |
| Epoch:  11 | Batch:   5000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.0780 | Perplexity: 8760.4619 |
| Epoch:  11 | Batch:   5200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0057 | Mean Training Loss: 9.0792 | Perplexity: 8770.8027 |
| Epoch:  11 | Batch:   5400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.0675 | Perplexity: 8668.5781 |
| Epoch:  11 | Batch:   5600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.0775 | Perplexity: 8756.0684 |
| Epoch:  11 | Batch:   5800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.0127 | Perplexity: 8206.7754 |
| Epoch:  11 | Batch:   6000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.9441 | Perplexity: 7662.6177 |
| Epoch:  11 | Batch:   6200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.9058 | Perplexity: 7374.9165 |
| Epoch:  11 | Batch:   6400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0063 | Mean Training Loss: 8.8451 | Perplexity: 6940.0229 |
| Epoch:  11 | Batch:   6600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.8661 | Perplexity: 7087.7500 |
| Epoch:  11 | Batch:   6800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.8938 | Perplexity: 7286.8975 |
| Epoch:  11 | Batch:   7000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.9100 | Perplexity: 7405.3911 |
| Epoch:  11 | Batch:   7200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.9312 | Perplexity: 7564.0483 |
| Epoch:  11 | Batch:   7400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 8.9532 | Perplexity: 7732.8496 |
| Epoch:  11 | Batch:   7600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.9739 | Perplexity: 7894.7041 |
| Epoch:  11 | Batch:   7800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 8.9926 | Perplexity: 8043.3765 |
| Epoch:  11 | Batch:   8000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.0116 | Perplexity: 8197.3965 |
| Epoch:  11 | Batch:   8200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 9.0260 | Perplexity: 8316.7646 |
| Epoch:  11 | Batch:   8400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.0346 | Perplexity: 8388.4873 |
| Epoch:  11 | Batch:   8600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.0504 | Perplexity: 8521.5215 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| End of Epoch:  11 | Time Taken: 49.0983 | Training Loss: 9.0567 | Training Perplexity: 8576.1367 | Validation Loss: 8.8509 | Validation Perplexity: 6980.7197 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| Epoch:  12 | Batch:    200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.1137 | Perplexity: 9078.8408 |
| Epoch:  12 | Batch:    400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 9.2511 | Perplexity: 10415.7148 |
| Epoch:  12 | Batch:    600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 9.1599 | Perplexity: 9507.8682 |
| Epoch:  12 | Batch:    800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.2001 | Perplexity: 9898.5146 |
| Epoch:  12 | Batch:   1000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.3086 | Perplexity: 11032.9707 |
| Epoch:  12 | Batch:   1200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.3649 | Perplexity: 11671.5898 |
| Epoch:  12 | Batch:   1400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.3670 | Perplexity: 11695.5693 |
| Epoch:  12 | Batch:   1600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.3981 | Perplexity: 12065.7559 |
| Epoch:  12 | Batch:   1800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.4280 | Perplexity: 12431.3838 |
| Epoch:  12 | Batch:   2000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.4164 | Perplexity: 12288.6748 |
| Epoch:  12 | Batch:   2200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.4355 | Perplexity: 12524.6191 |
| Epoch:  12 | Batch:   2400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.2977 | Perplexity: 10912.3906 |
| Epoch:  12 | Batch:   2600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.2885 | Perplexity: 10813.1055 |
| Epoch:  12 | Batch:   2800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.2558 | Perplexity: 10465.0098 |
| Epoch:  12 | Batch:   3000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.2443 | Perplexity: 10345.9307 |
| Epoch:  12 | Batch:   3200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.1757 | Perplexity: 9659.3359 |
| Epoch:  12 | Batch:   3400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.1285 | Perplexity: 9214.5508 |
| Epoch:  12 | Batch:   3600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.1027 | Perplexity: 8979.5322 |
| Epoch:  12 | Batch:   3800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.0779 | Perplexity: 8759.5586 |
| Epoch:  12 | Batch:   4000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.0447 | Perplexity: 8473.5303 |
| Epoch:  12 | Batch:   4200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.0121 | Perplexity: 8201.5098 |
| Epoch:  12 | Batch:   4400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0028 | Mean Training Loss: 8.9979 | Perplexity: 8086.3628 |
| Epoch:  12 | Batch:   4600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0036 | Mean Training Loss: 9.0031 | Perplexity: 8128.1914 |
| Epoch:  12 | Batch:   4800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.0141 | Perplexity: 8218.2021 |
| Epoch:  12 | Batch:   5000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.0237 | Perplexity: 8297.1494 |
| Epoch:  12 | Batch:   5200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.0252 | Perplexity: 8310.1523 |
| Epoch:  12 | Batch:   5400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.0138 | Perplexity: 8215.9609 |
| Epoch:  12 | Batch:   5600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0045 | Mean Training Loss: 9.0243 | Perplexity: 8302.1758 |
| Epoch:  12 | Batch:   5800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 8.9605 | Perplexity: 7789.4570 |
| Epoch:  12 | Batch:   6000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0046 | Mean Training Loss: 8.8927 | Perplexity: 7278.9727 |
| Epoch:  12 | Batch:   6200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.8550 | Perplexity: 7009.3784 |
| Epoch:  12 | Batch:   6400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0038 | Mean Training Loss: 8.7950 | Perplexity: 6600.8286 |
| Epoch:  12 | Batch:   6600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 8.8164 | Perplexity: 6744.1587 |
| Epoch:  12 | Batch:   6800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 8.8443 | Perplexity: 6934.4189 |
| Epoch:  12 | Batch:   7000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 8.8604 | Perplexity: 7047.0942 |
| Epoch:  12 | Batch:   7200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.8811 | Perplexity: 7194.9590 |
| Epoch:  12 | Batch:   7400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 8.9027 | Perplexity: 7351.9468 |
| Epoch:  12 | Batch:   7600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.9231 | Perplexity: 7503.2021 |
| Epoch:  12 | Batch:   7800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 8.9414 | Perplexity: 7641.7749 |
| Epoch:  12 | Batch:   8000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 8.9601 | Perplexity: 7786.3447 |
| Epoch:  12 | Batch:   8200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.9746 | Perplexity: 7899.9165 |
| Epoch:  12 | Batch:   8400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.9825 | Perplexity: 7962.7876 |
| Epoch:  12 | Batch:   8600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.9985 | Perplexity: 8090.7983 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| End of Epoch:  12 | Time Taken: 49.1100 | Training Loss: 9.0049 | Training Perplexity: 8143.2046 | Validation Loss: 8.8037 | Validation Perplexity: 6658.8267 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| Epoch:  13 | Batch:    200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.0726 | Perplexity: 8713.2520 |
| Epoch:  13 | Batch:    400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.2073 | Perplexity: 9969.8242 |
| Epoch:  13 | Batch:    600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.1115 | Perplexity: 9058.9141 |
| Epoch:  13 | Batch:    800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.1502 | Perplexity: 9416.6816 |
| Epoch:  13 | Batch:   1000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.2568 | Perplexity: 10475.7148 |
| Epoch:  13 | Batch:   1200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.3118 | Perplexity: 11067.5254 |
| Epoch:  13 | Batch:   1400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.3144 | Perplexity: 11096.2607 |
| Epoch:  13 | Batch:   1600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.3444 | Perplexity: 11435.1045 |
| Epoch:  13 | Batch:   1800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.3746 | Perplexity: 11784.9717 |
| Epoch:  13 | Batch:   2000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.3637 | Perplexity: 11656.9961 |
| Epoch:  13 | Batch:   2200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.3836 | Perplexity: 11891.4453 |
| Epoch:  13 | Batch:   2400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.2452 | Perplexity: 10354.4590 |
| Epoch:  13 | Batch:   2600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.2343 | Perplexity: 10242.2227 |
| Epoch:  13 | Batch:   2800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.2025 | Perplexity: 9921.9248 |
| Epoch:  13 | Batch:   3000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.1909 | Perplexity: 9807.1924 |
| Epoch:  13 | Batch:   3200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.1232 | Perplexity: 9165.5137 |
| Epoch:  13 | Batch:   3400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.0766 | Perplexity: 8748.2812 |
| Epoch:  13 | Batch:   3600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.0510 | Perplexity: 8527.3340 |
| Epoch:  13 | Batch:   3800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.0269 | Perplexity: 8324.0811 |
| Epoch:  13 | Batch:   4000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0052 | Mean Training Loss: 8.9940 | Perplexity: 8054.5605 |
| Epoch:  13 | Batch:   4200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 8.9614 | Perplexity: 7795.9224 |
| Epoch:  13 | Batch:   4400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 8.9474 | Perplexity: 7687.8193 |
| Epoch:  13 | Batch:   4600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0038 | Mean Training Loss: 8.9527 | Perplexity: 7728.6255 |
| Epoch:  13 | Batch:   4800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.9638 | Perplexity: 7815.2549 |
| Epoch:  13 | Batch:   5000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 8.9737 | Perplexity: 7892.7476 |
| Epoch:  13 | Batch:   5200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 8.9755 | Perplexity: 7906.8960 |
| Epoch:  13 | Batch:   5400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.9646 | Perplexity: 7821.4058 |
| Epoch:  13 | Batch:   5600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.9755 | Perplexity: 7907.1069 |
| Epoch:  13 | Batch:   5800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.9123 | Perplexity: 7422.8062 |
| Epoch:  13 | Batch:   6000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 8.8454 | Perplexity: 6942.2271 |
| Epoch:  13 | Batch:   6200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 8.8087 | Perplexity: 6692.2432 |
| Epoch:  13 | Batch:   6400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.7494 | Perplexity: 6307.1084 |
| Epoch:  13 | Batch:   6600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.7711 | Perplexity: 6445.0190 |
| Epoch:  13 | Batch:   6800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 8.7993 | Perplexity: 6629.2808 |
| Epoch:  13 | Batch:   7000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.8155 | Perplexity: 6737.7686 |
| Epoch:  13 | Batch:   7200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.8358 | Perplexity: 6876.2568 |
| Epoch:  13 | Batch:   7400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 8.8571 | Perplexity: 7023.9731 |
| Epoch:  13 | Batch:   7600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.8772 | Perplexity: 7166.3687 |
| Epoch:  13 | Batch:   7800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.8952 | Perplexity: 7296.5845 |
| Epoch:  13 | Batch:   8000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 8.9138 | Perplexity: 7433.6597 |
| Epoch:  13 | Batch:   8200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.9283 | Perplexity: 7542.5029 |
| Epoch:  13 | Batch:   8400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.9355 | Perplexity: 7597.1523 |
| Epoch:  13 | Batch:   8600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.9516 | Perplexity: 7720.2124 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| End of Epoch:  13 | Time Taken: 49.1431 | Training Loss: 8.9580 | Training Perplexity: 7769.9443 | Validation Loss: 8.7596 | Validation Perplexity: 6371.7549 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| Epoch:  14 | Batch:    200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.0310 | Perplexity: 8358.2627 |
| Epoch:  14 | Batch:    400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.1656 | Perplexity: 9562.7109 |
| Epoch:  14 | Batch:    600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.0670 | Perplexity: 8664.5283 |
| Epoch:  14 | Batch:    800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.1047 | Perplexity: 8997.6709 |
| Epoch:  14 | Batch:   1000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.2100 | Perplexity: 9997.0166 |
| Epoch:  14 | Batch:   1200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.2623 | Perplexity: 10532.9150 |
| Epoch:  14 | Batch:   1400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.2659 | Perplexity: 10571.6094 |
| Epoch:  14 | Batch:   1600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.2946 | Perplexity: 10879.4502 |
| Epoch:  14 | Batch:   1800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.3245 | Perplexity: 11209.7393 |
| Epoch:  14 | Batch:   2000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.3147 | Perplexity: 11099.4570 |
| Epoch:  14 | Batch:   2200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.3351 | Perplexity: 11328.6221 |
| Epoch:  14 | Batch:   2400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.1970 | Perplexity: 9867.0635 |
| Epoch:  14 | Batch:   2600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 9.1847 | Perplexity: 9746.4746 |
| Epoch:  14 | Batch:   2800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.1533 | Perplexity: 9445.9854 |
| Epoch:  14 | Batch:   3000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.1415 | Perplexity: 9334.8145 |
| Epoch:  14 | Batch:   3200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0052 | Mean Training Loss: 9.0748 | Perplexity: 8732.4766 |
| Epoch:  14 | Batch:   3400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.0288 | Perplexity: 8339.7900 |
| Epoch:  14 | Batch:   3600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.0042 | Perplexity: 8136.8154 |
| Epoch:  14 | Batch:   3800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.9805 | Perplexity: 7946.8638 |
| Epoch:  14 | Batch:   4000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.9476 | Perplexity: 7689.7329 |
| Epoch:  14 | Batch:   4200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.9149 | Perplexity: 7441.7241 |
| Epoch:  14 | Batch:   4400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.9012 | Perplexity: 7340.5483 |
| Epoch:  14 | Batch:   4600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.9064 | Perplexity: 7379.2432 |
| Epoch:  14 | Batch:   4800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 8.9176 | Perplexity: 7462.3906 |
| Epoch:  14 | Batch:   5000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.9273 | Perplexity: 7535.1416 |
| Epoch:  14 | Batch:   5200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.9298 | Perplexity: 7553.7471 |
| Epoch:  14 | Batch:   5400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.9192 | Perplexity: 7474.0215 |
| Epoch:  14 | Batch:   5600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.9305 | Perplexity: 7559.3394 |
| Epoch:  14 | Batch:   5800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 8.8680 | Perplexity: 7101.1055 |
| Epoch:  14 | Batch:   6000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.8019 | Perplexity: 6646.8862 |
| Epoch:  14 | Batch:   6200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.7657 | Perplexity: 6410.6475 |
| Epoch:  14 | Batch:   6400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.7069 | Perplexity: 6044.6577 |
| Epoch:  14 | Batch:   6600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.7287 | Perplexity: 6177.9731 |
| Epoch:  14 | Batch:   6800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0045 | Mean Training Loss: 8.7570 | Perplexity: 6354.9390 |
| Epoch:  14 | Batch:   7000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.7732 | Perplexity: 6458.9492 |
| Epoch:  14 | Batch:   7200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.7932 | Perplexity: 6589.6079 |
| Epoch:  14 | Batch:   7400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.8142 | Perplexity: 6729.2085 |
| Epoch:  14 | Batch:   7600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.8342 | Perplexity: 6865.1704 |
| Epoch:  14 | Batch:   7800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.8519 | Perplexity: 6987.5601 |
| Epoch:  14 | Batch:   8000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.8703 | Perplexity: 7117.5200 |
| Epoch:  14 | Batch:   8200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 8.8849 | Perplexity: 7222.4165 |
| Epoch:  14 | Batch:   8400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.8915 | Perplexity: 7269.8359 |
| Epoch:  14 | Batch:   8600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 8.9077 | Perplexity: 7388.9048 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| End of Epoch:  14 | Time Taken: 49.1049 | Training Loss: 8.9143 | Training Perplexity: 7437.3115 | Validation Loss: 8.7178 | Validation Perplexity: 6110.9253 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| Epoch:  15 | Batch:    200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.9979 | Perplexity: 8086.4785 |
| Epoch:  15 | Batch:    400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0052 | Mean Training Loss: 9.1288 | Perplexity: 9217.0029 |
| Epoch:  15 | Batch:    600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.0270 | Perplexity: 8324.5254 |
| Epoch:  15 | Batch:    800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.0627 | Perplexity: 8627.4893 |
| Epoch:  15 | Batch:   1000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.1655 | Perplexity: 9561.3799 |
| Epoch:  15 | Batch:   1200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.2152 | Perplexity: 10048.4502 |
| Epoch:  15 | Batch:   1400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.2192 | Perplexity: 10089.3945 |
| Epoch:  15 | Batch:   1600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.2476 | Perplexity: 10379.9678 |
| Epoch:  15 | Batch:   1800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.2776 | Perplexity: 10696.0820 |
| Epoch:  15 | Batch:   2000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.2686 | Perplexity: 10600.3613 |
| Epoch:  15 | Batch:   2200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.2906 | Perplexity: 10835.3105 |
| Epoch:  15 | Batch:   2400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.1529 | Perplexity: 9442.0498 |
| Epoch:  15 | Batch:   2600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.1391 | Perplexity: 9312.2656 |
| Epoch:  15 | Batch:   2800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.1081 | Perplexity: 9028.1592 |
| Epoch:  15 | Batch:   3000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0053 | Mean Training Loss: 9.0958 | Perplexity: 8918.0605 |
| Epoch:  15 | Batch:   3200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.0299 | Perplexity: 8349.1006 |
| Epoch:  15 | Batch:   3400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.9843 | Perplexity: 7977.0991 |
| Epoch:  15 | Batch:   3600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 8.9601 | Perplexity: 7786.2412 |
| Epoch:  15 | Batch:   3800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.9368 | Perplexity: 7606.9971 |
| Epoch:  15 | Batch:   4000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.9042 | Perplexity: 7362.8574 |
| Epoch:  15 | Batch:   4200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.8715 | Perplexity: 7126.0776 |
| Epoch:  15 | Batch:   4400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 8.8580 | Perplexity: 7030.4067 |
| Epoch:  15 | Batch:   4600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0037 | Mean Training Loss: 8.8634 | Perplexity: 7068.2148 |
| Epoch:  15 | Batch:   4800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.8747 | Perplexity: 7149.0239 |
| Epoch:  15 | Batch:   5000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.8845 | Perplexity: 7219.0215 |
| Epoch:  15 | Batch:   5200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 8.8869 | Perplexity: 7236.3774 |
| Epoch:  15 | Batch:   5400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.8765 | Perplexity: 7161.9624 |
| Epoch:  15 | Batch:   5600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 8.8881 | Perplexity: 7245.0713 |
| Epoch:  15 | Batch:   5800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 8.8262 | Perplexity: 6810.3027 |
| Epoch:  15 | Batch:   6000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 8.7608 | Perplexity: 6379.0449 |
| Epoch:  15 | Batch:   6200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.7251 | Perplexity: 6155.2021 |
| Epoch:  15 | Batch:   6400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.6670 | Perplexity: 5807.8374 |
| Epoch:  15 | Batch:   6600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 8.6889 | Perplexity: 5936.6260 |
| Epoch:  15 | Batch:   6800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.7174 | Perplexity: 6108.1519 |
| Epoch:  15 | Batch:   7000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.7336 | Perplexity: 6207.8989 |
| Epoch:  15 | Batch:   7200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.7534 | Perplexity: 6332.2646 |
| Epoch:  15 | Batch:   7400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.7740 | Perplexity: 6463.6636 |
| Epoch:  15 | Batch:   7600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.7935 | Perplexity: 6591.5122 |
| Epoch:  15 | Batch:   7800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 8.8110 | Perplexity: 6707.6548 |
| Epoch:  15 | Batch:   8000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.8294 | Perplexity: 6831.8931 |
| Epoch:  15 | Batch:   8200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 8.8441 | Perplexity: 6933.2817 |
| Epoch:  15 | Batch:   8400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.8500 | Perplexity: 6974.2651 |
| Epoch:  15 | Batch:   8600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.8664 | Perplexity: 7089.4263 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| End of Epoch:  15 | Time Taken: 49.1158 | Training Loss: 8.8729 | Training Perplexity: 7136.2041 | Validation Loss: 8.6797 | Validation Perplexity: 5882.1187 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| Epoch:  16 | Batch:    200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.9656 | Perplexity: 7829.1973 |
| Epoch:  16 | Batch:    400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.0962 | Perplexity: 8921.1309 |
| Epoch:  16 | Batch:    600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.9918 | Perplexity: 8037.1191 |
| Epoch:  16 | Batch:    800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.0253 | Perplexity: 8310.4854 |
| Epoch:  16 | Batch:   1000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.1243 | Perplexity: 9175.4756 |
| Epoch:  16 | Batch:   1200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.1731 | Perplexity: 9634.8721 |
| Epoch:  16 | Batch:   1400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.1776 | Perplexity: 9678.0537 |
| Epoch:  16 | Batch:   1600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.2054 | Perplexity: 9950.4287 |
| Epoch:  16 | Batch:   1800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.2348 | Perplexity: 10247.9678 |
| Epoch:  16 | Batch:   2000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.2266 | Perplexity: 10163.5352 |
| Epoch:  16 | Batch:   2200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.2490 | Perplexity: 10394.4902 |
| Epoch:  16 | Batch:   2400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.1115 | Perplexity: 9058.7246 |
| Epoch:  16 | Batch:   2600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.0961 | Perplexity: 8920.7744 |
| Epoch:  16 | Batch:   2800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.0654 | Perplexity: 8650.4678 |
| Epoch:  16 | Batch:   3000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.0528 | Perplexity: 8542.7588 |
| Epoch:  16 | Batch:   3200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 8.9875 | Perplexity: 8002.1523 |
| Epoch:  16 | Batch:   3400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.9423 | Perplexity: 7648.9717 |
| Epoch:  16 | Batch:   3600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 8.9186 | Perplexity: 7469.5962 |
| Epoch:  16 | Batch:   3800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.8958 | Perplexity: 7301.5684 |
| Epoch:  16 | Batch:   4000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 8.8633 | Perplexity: 7067.8984 |
| Epoch:  16 | Batch:   4200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 8.8306 | Perplexity: 6840.7012 |
| Epoch:  16 | Batch:   4400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.8173 | Perplexity: 6750.0718 |
| Epoch:  16 | Batch:   4600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.8227 | Perplexity: 6786.3530 |
| Epoch:  16 | Batch:   4800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0046 | Mean Training Loss: 8.8343 | Perplexity: 6865.7661 |
| Epoch:  16 | Batch:   5000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.8441 | Perplexity: 6933.3545 |
| Epoch:  16 | Batch:   5200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.8468 | Perplexity: 6952.0854 |
| Epoch:  16 | Batch:   5400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 8.8368 | Perplexity: 6883.0469 |
| Epoch:  16 | Batch:   5600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.8487 | Perplexity: 6965.5708 |
| Epoch:  16 | Batch:   5800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.7877 | Perplexity: 6553.2910 |
| Epoch:  16 | Batch:   6000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0045 | Mean Training Loss: 8.7230 | Perplexity: 6142.3013 |
| Epoch:  16 | Batch:   6200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.6880 | Perplexity: 5931.5781 |
| Epoch:  16 | Batch:   6400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.6304 | Perplexity: 5599.3105 |
| Epoch:  16 | Batch:   6600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.6526 | Perplexity: 5724.8120 |
| Epoch:  16 | Batch:   6800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 8.6813 | Perplexity: 5891.4717 |
| Epoch:  16 | Batch:   7000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 8.6974 | Perplexity: 5987.3311 |
| Epoch:  16 | Batch:   7200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 8.7169 | Perplexity: 6105.0537 |
| Epoch:  16 | Batch:   7400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.7371 | Perplexity: 6229.5098 |
| Epoch:  16 | Batch:   7600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 8.7564 | Perplexity: 6351.4248 |
| Epoch:  16 | Batch:   7800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.7737 | Perplexity: 6461.8511 |
| Epoch:  16 | Batch:   8000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0052 | Mean Training Loss: 8.7918 | Perplexity: 6580.3140 |
| Epoch:  16 | Batch:   8200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0046 | Mean Training Loss: 8.8067 | Perplexity: 6678.6177 |
| Epoch:  16 | Batch:   8400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.8119 | Perplexity: 6713.8623 |
| Epoch:  16 | Batch:   8600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.8284 | Perplexity: 6825.1333 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| End of Epoch:  16 | Time Taken: 49.1206 | Training Loss: 8.8349 | Training Perplexity: 6870.0562 | Validation Loss: 8.6437 | Validation Perplexity: 5674.5220 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| Epoch:  17 | Batch:    200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.9367 | Perplexity: 7606.2793 |
| Epoch:  17 | Batch:    400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.0639 | Perplexity: 8637.5752 |
| Epoch:  17 | Batch:    600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.9568 | Perplexity: 7760.3765 |
| Epoch:  17 | Batch:    800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.9886 | Perplexity: 8011.4985 |
| Epoch:  17 | Batch:   1000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.0859 | Perplexity: 8829.4912 |
| Epoch:  17 | Batch:   1200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.1322 | Perplexity: 9248.6035 |
| Epoch:  17 | Batch:   1400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.1373 | Perplexity: 9295.9834 |
| Epoch:  17 | Batch:   1600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.1650 | Perplexity: 9556.3477 |
| Epoch:  17 | Batch:   1800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.1943 | Perplexity: 9840.9854 |
| Epoch:  17 | Batch:   2000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.1864 | Perplexity: 9763.6201 |
| Epoch:  17 | Batch:   2200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.2096 | Perplexity: 9992.6797 |
| Epoch:  17 | Batch:   2400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.0727 | Perplexity: 8714.3330 |
| Epoch:  17 | Batch:   2600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0052 | Mean Training Loss: 9.0560 | Perplexity: 8569.4492 |
| Epoch:  17 | Batch:   2800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.0257 | Perplexity: 8314.1396 |
| Epoch:  17 | Batch:   3000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.0128 | Perplexity: 8207.3857 |
| Epoch:  17 | Batch:   3200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 8.9483 | Perplexity: 7694.7803 |
| Epoch:  17 | Batch:   3400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.9037 | Perplexity: 7359.2217 |
| Epoch:  17 | Batch:   3600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.8807 | Perplexity: 7191.7480 |
| Epoch:  17 | Batch:   3800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 8.8588 | Perplexity: 7036.2217 |
| Epoch:  17 | Batch:   4000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 8.8263 | Perplexity: 6811.1211 |
| Epoch:  17 | Batch:   4200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.7934 | Perplexity: 6590.4380 |
| Epoch:  17 | Batch:   4400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.7804 | Perplexity: 6505.3198 |
| Epoch:  17 | Batch:   4600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.7856 | Perplexity: 6539.6743 |
| Epoch:  17 | Batch:   4800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.7972 | Perplexity: 6615.4937 |
| Epoch:  17 | Batch:   5000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.8071 | Perplexity: 6681.4272 |
| Epoch:  17 | Batch:   5200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 8.8101 | Perplexity: 6701.5420 |
| Epoch:  17 | Batch:   5400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.8005 | Perplexity: 6637.5679 |
| Epoch:  17 | Batch:   5600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 8.8125 | Perplexity: 6717.8267 |
| Epoch:  17 | Batch:   5800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.7520 | Perplexity: 6323.3154 |
| Epoch:  17 | Batch:   6000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0039 | Mean Training Loss: 8.6880 | Perplexity: 5931.0117 |
| Epoch:  17 | Batch:   6200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.6534 | Perplexity: 5729.3237 |
| Epoch:  17 | Batch:   6400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.5962 | Perplexity: 5411.0430 |
| Epoch:  17 | Batch:   6600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 8.6184 | Perplexity: 5532.5518 |
| Epoch:  17 | Batch:   6800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 8.6472 | Perplexity: 5694.4175 |
| Epoch:  17 | Batch:   7000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.6635 | Perplexity: 5787.6343 |
| Epoch:  17 | Batch:   7200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.6825 | Perplexity: 5899.0278 |
| Epoch:  17 | Batch:   7400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.7025 | Perplexity: 6017.9976 |
| Epoch:  17 | Batch:   7600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0028 | Mean Training Loss: 8.7217 | Perplexity: 6134.4277 |
| Epoch:  17 | Batch:   7800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 8.7386 | Perplexity: 6239.3140 |
| Epoch:  17 | Batch:   8000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 8.7569 | Perplexity: 6354.0845 |
| Epoch:  17 | Batch:   8200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.7717 | Perplexity: 6449.1753 |
| Epoch:  17 | Batch:   8400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 8.7763 | Perplexity: 6479.0928 |
| Epoch:  17 | Batch:   8600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.7929 | Perplexity: 6587.4341 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| End of Epoch:  17 | Time Taken: 49.0715 | Training Loss: 8.7995 | Training Perplexity: 6630.9751 | Validation Loss: 8.6104 | Validation Perplexity: 5488.1724 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| Epoch:  18 | Batch:    200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.9072 | Perplexity: 7385.1782 |
| Epoch:  18 | Batch:    400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.0348 | Perplexity: 8390.1035 |
| Epoch:  18 | Batch:    600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 8.9228 | Perplexity: 7501.1704 |
| Epoch:  18 | Batch:    800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.9535 | Perplexity: 7734.8262 |
| Epoch:  18 | Batch:   1000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.0490 | Perplexity: 8509.9082 |
| Epoch:  18 | Batch:   1200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.0944 | Perplexity: 8905.3379 |
| Epoch:  18 | Batch:   1400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.1001 | Perplexity: 8956.6025 |
| Epoch:  18 | Batch:   1600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.1273 | Perplexity: 9203.4316 |
| Epoch:  18 | Batch:   1800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.1574 | Perplexity: 9484.5215 |
| Epoch:  18 | Batch:   2000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0052 | Mean Training Loss: 9.1497 | Perplexity: 9411.3574 |
| Epoch:  18 | Batch:   2200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.1737 | Perplexity: 9639.7529 |
| Epoch:  18 | Batch:   2400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0037 | Mean Training Loss: 9.0368 | Perplexity: 8406.6270 |
| Epoch:  18 | Batch:   2600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.0183 | Perplexity: 8252.8076 |
| Epoch:  18 | Batch:   2800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.9886 | Perplexity: 8010.8413 |
| Epoch:  18 | Batch:   3000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0053 | Mean Training Loss: 8.9753 | Perplexity: 7905.2144 |
| Epoch:  18 | Batch:   3200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.9116 | Perplexity: 7417.5488 |
| Epoch:  18 | Batch:   3400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.8675 | Perplexity: 7097.2329 |
| Epoch:  18 | Batch:   3600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.8449 | Perplexity: 6938.6460 |
| Epoch:  18 | Batch:   3800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.8232 | Perplexity: 6790.1660 |
| Epoch:  18 | Batch:   4000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0069 | Mean Training Loss: 8.7908 | Perplexity: 6573.8096 |
| Epoch:  18 | Batch:   4200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.7582 | Perplexity: 6362.9194 |
| Epoch:  18 | Batch:   4400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.7457 | Perplexity: 6283.8076 |
| Epoch:  18 | Batch:   4600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0052 | Mean Training Loss: 8.7510 | Perplexity: 6317.1494 |
| Epoch:  18 | Batch:   4800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.7626 | Perplexity: 6390.4678 |
| Epoch:  18 | Batch:   5000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.7725 | Perplexity: 6454.3809 |
| Epoch:  18 | Batch:   5200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.7756 | Perplexity: 6474.0830 |
| Epoch:  18 | Batch:   5400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.7662 | Perplexity: 6413.4541 |
| Epoch:  18 | Batch:   5600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.7784 | Perplexity: 6492.6758 |
| Epoch:  18 | Batch:   5800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.7184 | Perplexity: 6114.3765 |
| Epoch:  18 | Batch:   6000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 8.6549 | Perplexity: 5738.1001 |
| Epoch:  18 | Batch:   6200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.6211 | Perplexity: 5547.5405 |
| Epoch:  18 | Batch:   6400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.5644 | Perplexity: 5241.7827 |
| Epoch:  18 | Batch:   6600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 8.5868 | Perplexity: 5360.5278 |
| Epoch:  18 | Batch:   6800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.6157 | Perplexity: 5517.7349 |
| Epoch:  18 | Batch:   7000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0052 | Mean Training Loss: 8.6319 | Perplexity: 5607.8770 |
| Epoch:  18 | Batch:   7200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.6509 | Perplexity: 5715.0913 |
| Epoch:  18 | Batch:   7400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.6706 | Perplexity: 5828.8345 |
| Epoch:  18 | Batch:   7600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 8.6895 | Perplexity: 5940.3750 |
| Epoch:  18 | Batch:   7800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0033 | Mean Training Loss: 8.7064 | Perplexity: 6041.6665 |
| Epoch:  18 | Batch:   8000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0044 | Mean Training Loss: 8.7245 | Perplexity: 6151.6045 |
| Epoch:  18 | Batch:   8200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 8.7394 | Perplexity: 6244.3501 |
| Epoch:  18 | Batch:   8400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 8.7436 | Perplexity: 6270.1230 |
| Epoch:  18 | Batch:   8600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.7603 | Perplexity: 6375.7915 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| End of Epoch:  18 | Time Taken: 49.1150 | Training Loss: 8.7670 | Training Perplexity: 6418.6436 | Validation Loss: 8.5791 | Validation Perplexity: 5319.0859 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| Epoch:  19 | Batch:    200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 8.8798 | Perplexity: 7185.5513 |
| Epoch:  19 | Batch:    400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.0074 | Perplexity: 8163.6235 |
| Epoch:  19 | Batch:    600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.8931 | Perplexity: 7281.5620 |
| Epoch:  19 | Batch:    800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.9228 | Perplexity: 7501.2134 |
| Epoch:  19 | Batch:   1000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.0166 | Perplexity: 8239.0381 |
| Epoch:  19 | Batch:   1200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.0598 | Perplexity: 8602.6113 |
| Epoch:  19 | Batch:   1400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.0664 | Perplexity: 8659.3486 |
| Epoch:  19 | Batch:   1600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.0935 | Perplexity: 8896.9512 |
| Epoch:  19 | Batch:   1800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.1228 | Perplexity: 9161.8262 |
| Epoch:  19 | Batch:   2000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 9.1159 | Perplexity: 9099.0898 |
| Epoch:  19 | Batch:   2200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.1405 | Perplexity: 9325.6943 |
| Epoch:  19 | Batch:   2400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0046 | Mean Training Loss: 9.0038 | Perplexity: 8134.2007 |
| Epoch:  19 | Batch:   2600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 8.9841 | Perplexity: 7974.9014 |
| Epoch:  19 | Batch:   2800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.9543 | Perplexity: 7741.0845 |
| Epoch:  19 | Batch:   3000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.9406 | Perplexity: 7636.1074 |
| Epoch:  19 | Batch:   3200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0052 | Mean Training Loss: 8.8774 | Perplexity: 7168.2280 |
| Epoch:  19 | Batch:   3400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.8335 | Perplexity: 6860.3921 |
| Epoch:  19 | Batch:   3600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.8112 | Perplexity: 6708.6719 |
| Epoch:  19 | Batch:   3800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.7898 | Perplexity: 6566.8291 |
| Epoch:  19 | Batch:   4000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.7577 | Perplexity: 6359.4741 |
| Epoch:  19 | Batch:   4200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.7252 | Perplexity: 6156.3877 |
| Epoch:  19 | Batch:   4400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 8.7129 | Perplexity: 6081.0498 |
| Epoch:  19 | Batch:   4600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.7181 | Perplexity: 6112.6914 |
| Epoch:  19 | Batch:   4800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.7297 | Perplexity: 6184.0503 |
| Epoch:  19 | Batch:   5000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 8.7397 | Perplexity: 6246.1133 |
| Epoch:  19 | Batch:   5200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.7429 | Perplexity: 6266.2856 |
| Epoch:  19 | Batch:   5400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.7338 | Perplexity: 6209.1123 |
| Epoch:  19 | Batch:   5600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 8.7463 | Perplexity: 6287.0864 |
| Epoch:  19 | Batch:   5800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.6869 | Perplexity: 5924.9971 |
| Epoch:  19 | Batch:   6000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.6240 | Perplexity: 5563.5991 |
| Epoch:  19 | Batch:   6200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.5905 | Perplexity: 5380.4048 |
| Epoch:  19 | Batch:   6400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 8.5343 | Perplexity: 5086.0459 |
| Epoch:  19 | Batch:   6600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.5566 | Perplexity: 5201.1592 |
| Epoch:  19 | Batch:   6800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.5858 | Perplexity: 5355.1777 |
| Epoch:  19 | Batch:   7000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0052 | Mean Training Loss: 8.6021 | Perplexity: 5443.0127 |
| Epoch:  19 | Batch:   7200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 8.6208 | Perplexity: 5545.6411 |
| Epoch:  19 | Batch:   7400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.6402 | Perplexity: 5654.6958 |
| Epoch:  19 | Batch:   7600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0061 | Mean Training Loss: 8.6590 | Perplexity: 5761.9263 |
| Epoch:  19 | Batch:   7800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.6757 | Perplexity: 5858.9570 |
| Epoch:  19 | Batch:   8000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0066 | Mean Training Loss: 8.6937 | Perplexity: 5965.0186 |
| Epoch:  19 | Batch:   8200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.7086 | Perplexity: 6054.7485 |
| Epoch:  19 | Batch:   8400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.7122 | Perplexity: 6076.3135 |
| Epoch:  19 | Batch:   8600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.7289 | Perplexity: 6179.1216 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| End of Epoch:  19 | Time Taken: 49.1043 | Training Loss: 8.7357 | Training Perplexity: 6221.1147 | Validation Loss: 8.5491 | Validation Perplexity: 5162.2144 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| Epoch:  20 | Batch:    200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 8.8585 | Perplexity: 7033.7192 |
| Epoch:  20 | Batch:    400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.9824 | Perplexity: 7961.9287 |
| Epoch:  20 | Batch:    600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.8656 | Perplexity: 7083.7896 |
| Epoch:  20 | Batch:    800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.8943 | Perplexity: 7290.4771 |
| Epoch:  20 | Batch:   1000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 8.9856 | Perplexity: 7987.2847 |
| Epoch:  20 | Batch:   1200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.0273 | Perplexity: 8327.4551 |
| Epoch:  20 | Batch:   1400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.0345 | Perplexity: 8387.6475 |
| Epoch:  20 | Batch:   1600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.0612 | Perplexity: 8614.6396 |
| Epoch:  20 | Batch:   1800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 9.0908 | Perplexity: 8873.0811 |
| Epoch:  20 | Batch:   2000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 9.0842 | Perplexity: 8815.2207 |
| Epoch:  20 | Batch:   2200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 9.1097 | Perplexity: 9042.9287 |
| Epoch:  20 | Batch:   2400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 8.9732 | Perplexity: 7888.6084 |
| Epoch:  20 | Batch:   2600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0015 | Mean Training Loss: 8.9518 | Perplexity: 7721.5752 |
| Epoch:  20 | Batch:   2800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.9228 | Perplexity: 7500.7769 |
| Epoch:  20 | Batch:   3000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.9091 | Perplexity: 7398.6362 |
| Epoch:  20 | Batch:   3200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.8464 | Perplexity: 6949.4937 |
| Epoch:  20 | Batch:   3400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.8026 | Perplexity: 6651.8008 |
| Epoch:  20 | Batch:   3600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 8.7806 | Perplexity: 6506.9141 |
| Epoch:  20 | Batch:   3800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 8.7597 | Perplexity: 6371.9980 |
| Epoch:  20 | Batch:   4000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 8.7279 | Perplexity: 6172.5605 |
| Epoch:  20 | Batch:   4200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.6953 | Perplexity: 5974.9360 |
| Epoch:  20 | Batch:   4400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.6831 | Perplexity: 5902.4097 |
| Epoch:  20 | Batch:   4600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0047 | Mean Training Loss: 8.6883 | Perplexity: 5933.1729 |
| Epoch:  20 | Batch:   4800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.7003 | Perplexity: 6004.6172 |
| Epoch:  20 | Batch:   5000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.7103 | Perplexity: 6065.3477 |
| Epoch:  20 | Batch:   5200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.7138 | Perplexity: 6086.5381 |
| Epoch:  20 | Batch:   5400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.7049 | Perplexity: 6032.1846 |
| Epoch:  20 | Batch:   5600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0041 | Mean Training Loss: 8.7175 | Perplexity: 6108.6357 |
| Epoch:  20 | Batch:   5800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.6587 | Perplexity: 5760.0142 |
| Epoch:  20 | Batch:   6000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0046 | Mean Training Loss: 8.5962 | Perplexity: 5411.1255 |
| Epoch:  20 | Batch:   6200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.5632 | Perplexity: 5235.6621 |
| Epoch:  20 | Batch:   6400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0024 | Mean Training Loss: 8.5074 | Perplexity: 4951.1196 |
| Epoch:  20 | Batch:   6600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 8.5299 | Perplexity: 5063.9326 |
| Epoch:  20 | Batch:   6800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.5590 | Perplexity: 5213.4751 |
| Epoch:  20 | Batch:   7000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0048 | Mean Training Loss: 8.5752 | Perplexity: 5298.4097 |
| Epoch:  20 | Batch:   7200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.5935 | Perplexity: 5396.3765 |
| Epoch:  20 | Batch:   7400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.6128 | Perplexity: 5501.6143 |
| Epoch:  20 | Batch:   7600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.6314 | Perplexity: 5604.8833 |
| Epoch:  20 | Batch:   7800/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0050 | Mean Training Loss: 8.6479 | Perplexity: 5698.0786 |
| Epoch:  20 | Batch:   8000/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 8.6657 | Perplexity: 5800.3428 |
| Epoch:  20 | Batch:   8200/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0051 | Mean Training Loss: 8.6807 | Perplexity: 5888.3486 |
| Epoch:  20 | Batch:   8400/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.6836 | Perplexity: 5905.2139 |
| Epoch:  20 | Batch:   8600/  8747 | Learning Rate: 0.0010000 | ms/batch 0.0049 | Mean Training Loss: 8.7004 | Perplexity: 6005.2588 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| End of Epoch:  20 | Time Taken: 49.1196 | Training Loss: 8.7072 | Training Perplexity: 6046.2783 | Validation Loss: 8.5219 | Validation Perplexity: 5023.3604 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
| End of Training | Test Loss: 8.4579 | Test Perplexity: 4712.3095703 |
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
