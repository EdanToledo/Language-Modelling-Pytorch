{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "### Imports",
   "metadata": {
    "tags": [],
    "cell_id": "00000-54b70f8f-2709-4d20-95cc-a66c80772a33",
    "deepnote_cell_type": "text-cell-h3"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00001-606b8437-3a36-46bd-8b9c-230ecd6f63c0",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "59ee8a20",
    "execution_start": 1623416567182,
    "execution_millis": 32,
    "deepnote_cell_type": "code"
   },
   "source": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\ntorch.manual_seed(42)",
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 1,
     "data": {
      "text/plain": "<torch._C.Generator at 0x7f3ef4698a70>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "",
   "metadata": {
    "tags": [],
    "cell_id": "00002-0fd56729-4be3-4b63-896e-f37a4ac61a19",
    "deepnote_cell_type": "text-cell-p"
   }
  },
  {
   "cell_type": "markdown",
   "source": "# Neural Network Model",
   "metadata": {
    "tags": [],
    "cell_id": "00000-310541f2-aaee-41ec-81f6-79e329d37479",
    "deepnote_cell_type": "text-cell-h1"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00001-5b141a37-3c71-42e8-b85f-8946e6167248",
    "deepnote_cell_type": "code"
   },
   "source": "class language_model(nn.Module):\n    def __init__(self,context,embedding_size,hidden_size,number_of_layers,vocab,learning_rate):\n        super(language_model,self).__init__()\n\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n        self.context = context\n        self.embedding_size = embedding_size\n        self.hidden_size = hidden_size\n        self.number_of_layers = number_of_layers\n        self.vocab = vocab\n\n        layers = []\n        for i in range(number_of_layers):\n            layers.append(nn.Linear(hidden_size,hidden_size))\n\n        self.model = nn.Sequential(\n            nn.Embedding(vocab,embedding_size),\n            nn.Linear(vocab*context,hidden_size),\n            layers,\n            nn.Linear(hidden_size,vocab),\n            nn.LogSoftmax(dim=1)\n        ).to(self.device)\n\n        self.loss_function = nn.CrossEntropyLoss()\n        self.optimizer = optim.SGD(self.model.parameters(), lr=learning_rate)\n    \n    def forward(self,input_data):\n        return self.model(input_data)\n\n\n    def train(self,ngrams,word_to_id,num_epochs):\n        self.model.train()\n        for epoch in range(num_epochs):\n            total_loss = 0\n            for context_words, current_word in ngrams:\n\n                context_word_ids = torch.tensor([word_to_id[word] for word in context_words], dtype=torch.long).to(self.device)\n\n                self.model.zero_grad()\n\n                log_probs = self.model(context_word_ids)\n               \n                loss = self.loss_function(log_probs, torch.tensor([word_to_id[current_word]], dtype=torch.long).to(self.device))\n\n                loss.backward()\n                self.optimizer.step()\n\n                total_loss += loss.item()\n            losses.append(total_loss)\n            print(\"Loss after Epoch\",epoch,\":\",total_loss)\n        print(losses)\n\n\n    def test(self,ngrams,word_to_id):\n        self.model.eval()\n        with torch.no_grad():\n            num_correct = 0\n            total=0\n            for context_words, current_word in ngrams:\n\n                    context_word_ids = torch.tensor([word_to_id[word] for word in context_words], dtype=torch.long).to(self.device)\n\n                    log_probs = self.model(context_word_ids)\n\n                    word_index = torch.argmax(log_probs)\n\n                    if word_to_id[current_word] == word_index:\n                        num_correct+=1\n\n                    total+=1\n\n                    loss = self.loss_function(log_probs, torch.tensor([word_to_id[current_word]], dtype=torch.long).to(self.device))\n\n                    total_loss += loss.item()\n            \n            print(\"Total Loss:\",total_loss)\n            print(\"Accuracy:\",num_correct/total_loss)\n\n\n\n    \n\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=aa6c7eb5-d731-4a9a-8f73-5821cfc2b6d5' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_notebook_id": "410cd5a8-5d9a-4174-9bc1-d2db225007fe",
  "deepnote_execution_queue": []
 }
}